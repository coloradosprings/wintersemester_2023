{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Kernel Methoden\n\nIn dieser Übung werden wir und verschiedene Kernel Methoden ansehen und diese vergleichen.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-06T13:20:15.291597Z","iopub.execute_input":"2023-11-06T13:20:15.292686Z","iopub.status.idle":"2023-11-06T13:20:16.481817Z","shell.execute_reply.started":"2023-11-06T13:20:15.292561Z","shell.execute_reply":"2023-11-06T13:20:16.480932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wir verwenden das *Red Wine Quality* Datenset und wollen ein Modell trainieren, welches die Qualität des Weines anhand verschiedener Parameter vorhersagen kann. Zuerst laden wir das Datenset als *pandas DataFrame*:","metadata":{}},{"cell_type":"code","source":"\ndf = pd.read_csv(\"/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv\")\ndata_train, data_test = train_test_split(df.copy(), test_size=0.2, random_state=42)\ndata_train.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-02T16:26:30.004227Z","iopub.execute_input":"2022-05-02T16:26:30.004587Z","iopub.status.idle":"2022-05-02T16:26:30.063485Z","shell.execute_reply.started":"2022-05-02T16:26:30.004554Z","shell.execute_reply":"2022-05-02T16:26:30.06257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Die Qualität ist ein Integer Wert zwischen 3 und 8. Wir können sowohl Klassifikations- als auch Regressionsmodelle verwenden, da es eine Skala ist.","metadata":{}},{"cell_type":"code","source":"print(\"Min Quality:\", df.quality.min())\nprint(\"Max Quality:\", df.quality.max())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wir können die Verteilung der Qualität in einem Histogram plotten und sehen, dass ein Großteil der Weine eine Qualität $\\leq 6$ besitzen.\n","metadata":{}},{"cell_type":"code","source":"df.quality.hist()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1a) Kernel Methoden Vergleich\n\nDer folgende Code verwendet eine *Kernel Ridge Regression* um die Qualität vorherzusagen. \n","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_absolute_error, make_scorer\n\nX_train, y_train = data_train.drop([\"quality\"], axis=1), data_train.quality\nX_test, y_test = data_test.drop([\"quality\"], axis=1), data_test.quality\n\n# In sklearn ist ein höherer Score immer besser. der mean_absolute_error ist aber am besten, wenn er klein ist.\n# Wenn wir den Scorer erstellen nehmen wir also -mean_absoute_error als Bewertungsmaß. Dazu setzten wir greater_is_better=False.\n# Dementsprechend werden die Scores im Grid Search auch negativ sein und der Score, der am nähesten zu 0 ist der beste.\nscore = make_scorer(mean_absolute_error, greater_is_better=False)  \n\n# make_scorer erstellt im Prinzip die folgende Funktion\n# def score(model, X_true, y_true)\n#     y_pred = model.predict(X_true)\n#     return - mean_absolute_error(y_true, y_pred)\n\npipeline = Pipeline([\n    (\"scale\", StandardScaler()),\n    (\"ridge\", KernelRidge(kernel=\"rbf\"))\n])\n\nmodel = GridSearchCV(pipeline, [{\"ridge__alpha\": [0.001, 0.01, 0.1, 1], \"ridge__gamma\": [0.001, 0.01, 0.03, 0.05, 0.1], \"ridge__kernel\": [\"rbf\"]}], \n                     n_jobs=-1, scoring=score, cv = 5)\nmodel.fit(X_train, y_train)\npd.DataFrame(model.cv_results_).sort_values(\"rank_test_score\").head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Trainiere eine *Support Vektor Regression* und einen *Support Vektor Klassifikator* mit einem *`rbf` Kernel*. Benutze einen StandardScaler als Vorbereitungsschritt und wähle die Hyperparameter mit `GridSearchCV`. Wir wollen das Modell anhand der *Mean Absolute Errors* bewerten. Setzte dazu `scoring=score` in `GridSearchCV`. Welches Modell ist das beste?\n\n---\nUm den Grid Search schneller zu machen, kannst du `n_jobs=-1` setzen. Dadurch werden die verschiedenen Modelle und Splits auf unterschiedliche Prozesse verteilt und parallel ausgeführt.\n\n---\n","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVR, SVC\n# SVR","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SVC","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Welchen Fehler (*Mean Absolute Error*) erzielt das beste Modell auf der Testmenge?","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1b) Binäre Support Vektor Klassifikation\nEin Gourmet-Restaurant will Wein einkaufen und möglichst keinen Wein mit schlechter Qualität in der Karte haben. Dazu will es das *Red Wine Quality* Datenset verwenden um einen Klassifikator zu trainieren, welcher guten Wein von schlechten unterscheiden kann. Guter Wein mit einer Qualität $\\gt 6$ bekommt das Label $1$ und schlechter Wein mit Qualität $\\leq 6$ bekommt das Label $0$. Für das Restaurant ist ein hoher *Precision Score* sehr wichtig. Das bedeutet, wenn der Klassifikator einen Wein als gut einstuft, dann soll dieser Wein mit hoher \"Wahrscheinlichkeit\" tatsächlich gut sein. Der *Recall Score*, die \"Wahrscheinlichkeit\", dass ein guter Wein als gut erkannt wird, ist eher nebensächlich. Mit anderen Worten, das Restaurant kann es eher verkraften einen guten Wein nicht anzubieten, als dass es dem Kunden einen schlechten Wein serviert.\n","metadata":{}},{"cell_type":"markdown","source":"Der folgende Code erstellt dieses neue *Target*. Beachte, dass die Bezeichung jetzt `X_train_clf` und `y_train_clf` ist.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold, cross_val_predict\nfrom sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, make_scorer\n\ndf_clf = df.copy()\n\ndf_clf[\"goodquality\"] = (df_clf.quality > 6).astype(int)\ndf_clf = df_clf.drop(\"quality\", axis=1)\ndata_train_clf, data_test_clf = train_test_split(df_clf, test_size=0.2, random_state=43, stratify=df_clf.goodquality)\n\n\nX_train_clf, y_train_clf = data_train_clf.drop([\"goodquality\"], axis=1), data_train_clf.goodquality\nX_test_clf, y_test_clf = data_test_clf.drop([\"goodquality\"], axis=1), data_test_clf.goodquality","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wir können sehen, dass das Datenset jetzt sehr unausgewogen ist und die positive Klasse eher selten ist.","metadata":{}},{"cell_type":"code","source":"y_train_clf.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Trainiere ein `SVC` Modell. Benutze wieder `StandardScaler`, `GridSearchCV` und `StratifiedKFold` (setze dazu `cv=StratifiedKFold()` in `GridSearchCV`).  Benutze den `f1_score` und setzte `probability=True` damit die `SVC` Wahrscheinlichkeiten berechnen kann.","metadata":{}},{"cell_type":"code","source":"scorer = make_scorer(f1_score)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Berechne die Wahrheitsmatrix des Trainingssets und des besten Modells. Benutze dazu `cross_val_predict`, benutze wieder `cv=StratifiedKFold()`.\n- Berechne *Recall* und *Precision Score* anhand des Trainingssets.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import confusion_matrix, recall_score, precision_score\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Plotte die Precision und den Recall gegen den Schwellenwert (Threshold; in $[0,1]$), welcher die Klassenzugehörigkeit festlegt. Wir verwenden `cross_val_predict` und setzen `method='predict_proba'` um die Klassenzugehörigkeitswahrscheinlichkeiten auszugeben.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import precision_recall_curve, roc_curve\n\ndef plot_precision_recall(model):\n    y_pred = cross_val_predict(model.best_estimator_, X_train_clf, y_train_clf, method='predict_proba', cv=StratifiedKFold(5))\n    \n    # wir nehmen die Klassenzugehörigkeitswahrscheinlichkeit der positiven Klasse\n    y_pred = y_pred[:, 1] \n    \n    precision, recall, thresholds = precision_recall_curve(y_train_clf, y_pred)\n\n    plt.figure()\n    plt.plot(thresholds, precision[:-1], \"b--\", label=\"Precision\")\n    plt.plot(thresholds, recall[:-1], \"g-\", label=\"Recall\")\n    plt.xlabel('Threshold')\n    plt.legend()\n    plt.grid()\n    plt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Plotte die ROC-Curve.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Das Restaurant will ein Modell, welches eine *Precision* von mindestens 80% hat. Welchen Schwellenwert (*Threshold*) würdest du wählen?\n- Wie hoch ist Precision und Recall auf dem Testset mit und ohne Berücksichtigung des Schwellenwerts?","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"finale Version","metadata":{}}]}