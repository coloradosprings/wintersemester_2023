{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Code Example\n",
    "# Let's walk through a code example. First the code.\n",
    "\n",
    "### imports\n",
    "import tensorflow as tf\n",
    "\n",
    "### constant data\n",
    "x  = [[0.,0.],[1.,1.],[1.,0.],[0.,1.]]\n",
    "y_ = [[0.],[0.],[1.],[1.]]\n",
    "\n",
    "### induction\n",
    "# 1x2 input -> 2x3 hidden sigmoid -> 3x1 sigmoid output\n",
    "\n",
    "# Layer 0 = the x2 inputs\n",
    "x0 = tf.constant( x  , dtype=tf.float32 )\n",
    "y0 = tf.constant( y_ , dtype=tf.float32 )\n",
    "\n",
    "# Layer 1 = the 2x3 hidden sigmoid\n",
    "m1 = tf.Variable( tf.random.uniform( [2,3] , minval=0.1 , maxval=0.9 , dtype=tf.float32  ))\n",
    "b1 = tf.Variable( tf.random.uniform( [3]   , minval=0.1 , maxval=0.9 , dtype=tf.float32  ))\n",
    "h1 = tf.sigmoid( tf.matmul( x0,m1 ) + b1 )\n",
    "\n",
    "# Layer 2 = the 3x1 sigmoid output\n",
    "m2 = tf.Variable( tf.random.uniform( [3,1] , minval=0.1 , maxval=0.9 , dtype=tf.float32  ))\n",
    "b2 = tf.Variable( tf.random.uniform( [1]   , minval=0.1 , maxval=0.9 , dtype=tf.float32  ))\n",
    "y_out = tf.sigmoid( tf.matmul( h1,m2 ) + b2 )\n",
    "\n",
    "\n",
    "### loss\n",
    "# loss : sum of the squares of y0 - y_out\n",
    "# @tf.function\n",
    "# def cost():\n",
    "#   loss = tf.reduce_sum( tf.square( y0 - y_out ) )\n",
    "#   return(loss)\n",
    "\n",
    "# trainable_vars = [m1,b1,m2,b2]\n",
    "# # training step : gradient decent (1.0) to minimize loss\n",
    "# train = tf.keras.optimizers.SGD(1.0).minimize(cost,trainable_vars)#tape= tf.GradientTape())\n",
    "\n",
    "\n",
    "# ### training\n",
    "# # run 500 times using all the X and Y\n",
    "# # print out the loss and any other interesting info\n",
    "# with tf.Session() as sess:\n",
    "#   sess.run( tf.global_variables_initializer() )\n",
    "#   for step in range(500) :\n",
    "#     sess.run(train)\n",
    "\n",
    "#   results = sess.run([m1,b1,m2,b2,y_out,loss])\n",
    "#   labels  = \"m1,b1,m2,b2,y_out,loss\".split(\",\")\n",
    "#   for label,result in zip(*(labels,results)) :\n",
    "#     print (\"\")\n",
    "#     print (label)\n",
    "#     print (result)\n",
    "\n",
    "# print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "tf.print(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = [1, 2, 3]\n",
    "# y_train = [1, 2, 3]\n",
    "\n",
    "# x_train = tf.constant( x_train  , dtype=tf.float32 )\n",
    "# y_train = tf.constant( y_train  , dtype=tf.float32 )\n",
    "# W = tf.Variable( tf.random.uniform( [3,1] , minval=0.1 , maxval=0.9 , dtype=tf.float32  ))\n",
    "# b = tf.Variable( tf.random.uniform( [1]   , minval=0.1 , maxval=0.9 , dtype=tf.float32  ))\n",
    "# y_out = tf.sigmoid( tf.matmul( x_train ,W) + b )\n",
    "# optimizer = tf.optimizers.SGD(learning_rate=0.01)\n",
    "# epochs = 2 \n",
    "# for _ in range(epochs):\n",
    "#     with tf.GradientTape(persistent=True) as tape:\n",
    "#         y_out = tf.sigmoid( tf.matmul( W,x_train ) + b )\n",
    "#         loss = tf.reduce_sum( tf.square( y_train - y_out ) )\n",
    "#     grad = tape.gradient(loss, [W,h])\n",
    "#     optimizer.apply_gradients(zip(grad, [W,h]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "### constant data\n",
    "x  = [[0.,0.],[1.,1.],[1.,0.],[0.,1.]]\n",
    "y_ = [[0.],[0.],[1.],[1.]]\n",
    "\n",
    "### induction\n",
    "# 1x2 input -> 2x3 hidden sigmoid -> 3x1 sigmoid output\n",
    "\n",
    "# Layer 0 = the x2 inputs\n",
    "x0 = tf.constant( x  , dtype=tf.float32 )\n",
    "y0 = tf.constant( y_ , dtype=tf.float32 )\n",
    "\n",
    "# Layer 1 = the 2x3 hidden sigmoid\n",
    "m1 = tf.Variable( tf.random.uniform( [2,3] , minval=0.1 , maxval=0.9 , dtype=tf.float32  ))\n",
    "b1 = tf.Variable( tf.random.uniform( [3]   , minval=0.1 , maxval=0.9 , dtype=tf.float32  ))\n",
    "h1 = tf.sigmoid( tf.matmul( x0,m1 ) + b1 )\n",
    "\n",
    "# Layer 2 = the 3x1 sigmoid output\n",
    "m2 = tf.Variable( tf.random.uniform( [3,1] , minval=0.1 , maxval=0.9 , dtype=tf.float32  ))\n",
    "b2 = tf.Variable( tf.random.uniform( [1]   , minval=0.1 , maxval=0.9 , dtype=tf.float32  ))\n",
    "y_out = tf.sigmoid( tf.matmul( h1,m2 ) + b2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.SGD(learning_rate=0.01)\n",
    "epochs = 100 \n",
    "for _ in range(epochs):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        y_out = tf.sigmoid( tf.matmul( h1,m2 ) + b2 )\n",
    "        loss = tf.reduce_sum( tf.square( y0 - y_out ) )\n",
    "    grad = tape.gradient(loss, trainable_vars)\n",
    "    optimizer.apply_gradients(zip(grad, trainable_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x  = [[0.,0.],[1.,1.],[1.,0.],[0.,1.]]\n",
    "y_ = [[0.],[0.],[1.],[1.]]\n",
    "\n",
    "### induction\n",
    "# 1x2 input -> 2x3 hidden sigmoid -> 3x1 sigmoid output\n",
    "\n",
    "# Layer 0 = the x2 inputs\n",
    "x0 = tf.constant( x  , dtype=tf.float32 )\n",
    "y0 = tf.constant( y_ , dtype=tf.float32 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.linspace(0, 20, 1000)\n",
    "\n",
    "m = 1.\n",
    "c = 0.1\n",
    "k = 1.\n",
    "y0 = 1.\n",
    "y0_prime = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ode(params, t):\n",
    "    _nn = lambda t: nn(params, t)\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        dnn = tape.gradient(_nn)\n",
    "        ddnn = tape.gradient(dnn)\n",
    "    return m * ddnn(t) + c * dnn(t) + k * _nn(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x  = [[0.,0.],[1.,1.],[1.,0.],[0.,1.]]\n",
    "y_ = [[0.],[0.],[1.],[1.]]\n",
    "\n",
    "### induction\n",
    "# 1x2 input -> 2x3 hidden sigmoid -> 3x1 sigmoid output\n",
    "\n",
    "# Layer 0 = the x2 inputs\n",
    "x0 = tf.constant( x  , dtype=tf.float32 )\n",
    "y0 = tf.constant( y_ , dtype=tf.float32 )\n",
    "\n",
    "# Layer 1 = the 2x3 hidden sigmoid\n",
    "m1 = tf.Variable( tf.random.uniform( [2,3] , minval=0.1 , maxval=0.9 , dtype=tf.float32  ))\n",
    "b1 = tf.Variable( tf.random.uniform( [3]   , minval=0.1 , maxval=0.9 , dtype=tf.float32  ))\n",
    "h1 = tf.sigmoid( tf.matmul( x0,m1 ) + b1 )\n",
    "\n",
    "# Layer 2 = the 3x1 sigmoid output\n",
    "m2 = tf.Variable( tf.random.uniform( [3,1] , minval=0.1 , maxval=0.9 , dtype=tf.float32  ))\n",
    "b2 = tf.Variable( tf.random.uniform( [1]   , minval=0.1 , maxval=0.9 , dtype=tf.float32  ))\n",
    "\n",
    "output = tf.tanh(x0 @m1 + b1) @ m2 + b2\n",
    "\n",
    "# create a one layer neural network with `tanh` activation function\n",
    "trainable_vars = [m1,b1,m2,b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(m1)\n",
    "    y_out = tf.sigmoid( output )\n",
    "    loss = tf.reduce_sum( tf.square( y0 - y_out ) )\n",
    "grad = tape.gradient(loss, trainable_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[2.0, 4.0], [6.0]]>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((1,)),\n",
    "    tf.keras.layers.Dense(units = 32, activation = 'tanh'),\n",
    "    tf.keras.layers.Dense(units = 32, activation = 'tanh'),\n",
    "    tf.keras.layers.Dense(units = 32, activation = 'tanh'),\n",
    "    tf.keras.layers.Dense(units = 1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.optimizers.SGD(learning_rate=0.01)\n",
    "epochs = 100 \n",
    "for _ in range(epochs):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        y_out = tf.sigmoid( tf.matmul( h1,m2 ) + b2 )\n",
    "        loss = tf.reduce_sum( tf.square( y0 - y_out ) )\n",
    "    grad = tape.gradient(loss, trainable_vars)\n",
    "    optimizer.apply_gradients(zip(grad, trainable_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainable_vars' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 2\u001b[0m line \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W1sdW50aXRsZWQ%3D?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tp:\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W1sdW50aXRsZWQ%3D?line=4'>5</a>\u001b[0m     \u001b[39m#your loss/cost function must always be contained within the gradient tape instantiation\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W1sdW50aXRsZWQ%3D?line=5'>6</a>\u001b[0m     cost_fn \u001b[39m=\u001b[39m cost()\n\u001b[1;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W1sdW50aXRsZWQ%3D?line=6'>7</a>\u001b[0m gradients \u001b[39m=\u001b[39m tp\u001b[39m.\u001b[39mgradient(cost_fn, trainable_vars)\n\u001b[0;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W1sdW50aXRsZWQ%3D?line=7'>8</a>\u001b[0m optimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(gradients, trainable_vars))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainable_vars' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = tf.optimizers.SGD(learning_rate=0.01)\n",
    "epochs = 100 \n",
    "for _ in range(epochs):\n",
    "    with tf.GradientTape() as tp:\n",
    "        #your loss/cost function must always be contained within the gradient tape instantiation\n",
    "        cost_fn = cost()\n",
    "    gradients = tp.gradient(cost_fn, trainable_vars)\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
