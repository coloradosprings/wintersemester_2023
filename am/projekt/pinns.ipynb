{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-11-20T19:43:24.439682Z","iopub.status.busy":"2022-11-20T19:43:24.439162Z","iopub.status.idle":"2022-11-20T19:43:26.929679Z","shell.execute_reply":"2022-11-20T19:43:26.928507Z","shell.execute_reply.started":"2022-11-20T19:43:24.439591Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'jax'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32mc:\\Users\\natsc\\Downloads\\pinns.ipynb Cell 1\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/natsc/Downloads/pinns.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjax\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/natsc/Downloads/pinns.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mjnp\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'jax'"]}],"source":["import jax\n","import jax.numpy as jnp"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-20T19:43:39.140148Z","iopub.status.busy":"2022-11-20T19:43:39.139751Z","iopub.status.idle":"2022-11-20T19:43:39.302888Z","shell.execute_reply":"2022-11-20T19:43:39.301707Z","shell.execute_reply.started":"2022-11-20T19:43:39.140116Z"},"trusted":true},"outputs":[],"source":["t = jnp.linspace(0, 20, 1000)\n","\n","m = 1.\n","c = 0.1\n","k = 1.\n","y0 = 1.\n","y0_prime = 0.\n","\n","\n","# create a one layer neural network with `tanh` activation function\n","def nn(params, t):\n","    return params['W2'] @ jnp.tanh(params['W1'] * t + params['b1']) + params['b2']\n","\n","\n","initializer = jax.nn.initializers.glorot_uniform()\n","key = jax.random.PRNGKey(42)\n","*init_keys, key = jax.random.split(key, 5)\n","\n","h = 30\n","params = {\n","    'W1': initializer(init_keys[0], (h, 1), jnp.float32)[:, 0],\n","    'W2': initializer(init_keys[1], (1, h), jnp.float32)[0, :],\n","    'b1': initializer(init_keys[2], (h, 1), jnp.float32)[:, 0],\n","    'b2': initializer(init_keys[3], (1, 1), jnp.float32)[0, 0],\n","}\n","\n","nn(params, t[0])"]},{"cell_type":"markdown","metadata":{},"source":["We want to train the neural network for the ODE \n","\n","$$\n","m * \\ddot y + c * \\dot y + k * y = 0,\n","$$\n","with $m = 1, c = 0.1$ and $k = 1$. \n","\n","Therefore we define an objective \n","\n","$$\n","\\mathcal{L}(\\mathbf{W}) = \\frac{1}{M}\\sum_{i=1}^M (m * \\ddot y_\\mathbf{W}(t_i) + c * \\dot y_\\mathbf{W}(t_i) + k * y_\\mathbf{W}(t_i)) ^ 2 + (y_\\mathbf{W}(0) - y_0) ^ 2 + (\\dot y_\\mathbf{W}(0) - \\dot y_0) ^ 2\n","$$"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-20T19:53:53.004288Z","iopub.status.busy":"2022-11-20T19:53:53.003506Z","iopub.status.idle":"2022-11-20T19:53:53.053988Z","shell.execute_reply":"2022-11-20T19:53:53.052945Z","shell.execute_reply.started":"2022-11-20T19:53:53.004247Z"},"trusted":true},"outputs":[],"source":["\n","def ode(params, t):\n","    _nn = lambda t: nn(params, t)\n","    dnn = jax.grad(_nn)\n","    ddnn = jax.grad(dnn)\n","    return m * ddnn(t) + c * dnn(t) + k * _nn(t)\n","\n","def objective(params, ts):\n","    ys = jax.vmap(ode, (None, 0))(params, ts)\n","    ode_loss = jnp.mean(ys ** 2)\n","    init_loss1 = (nn(params, 0.) - y0) ** 2\n","    init_loss2 = (jax.grad(nn, 1)(params, 0.) - y0_prime) ** 2\n","    return ode_loss + init_loss1 + init_loss2\n","\n","objective(params, t)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-20T19:55:24.148540Z","iopub.status.busy":"2022-11-20T19:55:24.147412Z","iopub.status.idle":"2022-11-20T19:55:41.839364Z","shell.execute_reply":"2022-11-20T19:55:41.838141Z","shell.execute_reply.started":"2022-11-20T19:55:24.148490Z"},"trusted":true},"outputs":[],"source":["import optax\n","\n","def fit(params: optax.Params, optimizer: optax.GradientTransformation, key) -> optax.Params:\n","    opt_state = optimizer.init(params)\n","\n","    @jax.jit\n","    def step(params, opt_state, batch):\n","        loss_value, grads = jax.value_and_grad(objective)(params, batch)\n","        updates, opt_state = optimizer.update(grads, opt_state, params)\n","        params = optax.apply_updates(params, updates)\n","        return params, opt_state, loss_value\n","    \n","    for epoch in range(5000):\n","        shuffle_key, key = jax.random.split(key)\n","        batches = jax.random.permutation(shuffle_key, t)\n","        batches = batches.reshape(10, -1)\n","        for batch in batches:\n","            params, opt_state, loss_value = step(params, opt_state, batch)\n","        if epoch % 100 == 0:\n","            print(f'epoch {epoch}, loss: {loss_value}')\n","    return params\n","\n","# Finally, we can fit our parametrized function using the Adam optimizer\n","# provided by optax.\n","optimizer = optax.adam(learning_rate=1e-2)\n","train_key, key = jax.random.split(key)\n","params = fit(params, optimizer, key)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-20T19:55:53.397693Z","iopub.status.busy":"2022-11-20T19:55:53.397280Z","iopub.status.idle":"2022-11-20T19:55:53.402420Z","shell.execute_reply":"2022-11-20T19:55:53.401268Z","shell.execute_reply.started":"2022-11-20T19:55:53.397658Z"},"trusted":true},"outputs":[],"source":["# import jaxopt\n","# solver = jaxopt.LBFGS(fun=objective)\n","# params = solver.run(params, t).params"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-20T19:54:31.059578Z","iopub.status.busy":"2022-11-20T19:54:31.059176Z","iopub.status.idle":"2022-11-20T19:54:31.066277Z","shell.execute_reply":"2022-11-20T19:54:31.065461Z","shell.execute_reply.started":"2022-11-20T19:54:31.059547Z"},"trusted":true},"outputs":[],"source":["def sol(t):\n","    r1 = - c / (2 * m) + 1 / (2*m) * (c ** 2 - 4 * k * m) ** (1 / 2)\n","    r2 = - c / (2 * m) - 1 / (2*m) * (c ** 2 - 4 * k * m) ** (1 / 2)\n","    c2 = r1 / (r1 - r2)\n","    c1 = 1 - c2\n","    return c1 * jnp.exp(r1 * t) + c2 * jnp.exp(r2 * t)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-20T19:55:44.902985Z","iopub.status.busy":"2022-11-20T19:55:44.902570Z","iopub.status.idle":"2022-11-20T19:55:45.183512Z","shell.execute_reply":"2022-11-20T19:55:45.182534Z","shell.execute_reply.started":"2022-11-20T19:55:44.902950Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","model = jax.vmap(lambda t: nn(params, t))\n","\n","plt.plot(t, jnp.real(sol(t)), label='true_sol')\n","plt.plot(t, model(t), label='pred_sol')\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":4}
