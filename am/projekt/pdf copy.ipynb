{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\frac{\\left(z - 1\\right) \\left(z + 1\\right) \\cos{\\left(z \\right)}}{z^{4} - z^{2} + 1}$"
      ],
      "text/plain": [
       "-(z - 1)*(z + 1)*cos(z)/(z**4 - z**2 + 1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculated solution\n",
    "z = symbols(\"z\",real=True)\n",
    "w,r,O,B = 1,1,1,1\n",
    "A = 1/(-z**2*O**2 + I*r*z*O + w**2)\n",
    "Z = A*E**(I*O*z)\n",
    "solution = factor( re(A)*re(E**(I*O*z)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a PINN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Wir versuchen die Gew√∂hnliche differentialgleichung zu approximieren\n",
    "\n",
    "$$\n",
    "m * \\ddot y + c * \\dot y + k * y = g(t),\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "<!-- with $m = 1, c = 0.1$ and $k = 1$.  -->\n",
    "\n",
    "with a neural network of the form\n",
    "\n",
    "$$\n",
    "\n",
    "{  L_{i} = \\large \\sigma_{i} \\left({ \\begin{bmatrix}\n",
    "&  &  \\\\\n",
    "& {\\large W_{i}} & \\\\\n",
    "&  &  \\\\\n",
    "\n",
    " \n",
    "\\end{bmatrix} * \n",
    "\\begin{bmatrix}\n",
    "  \\\\\n",
    "{\\large x_{i}}   \\\\\n",
    "  \\\\\n",
    "\n",
    " \n",
    "\\end{bmatrix} +\n",
    "\\begin{bmatrix}\n",
    "  \\\\\n",
    "{\\large b_{i}}   \\\\\n",
    " \\\\\n",
    "\n",
    " \n",
    "\\end{bmatrix} \n",
    "\n",
    "\n",
    " }\\right) }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "$$\n",
    "NN(t) =  ( L_{1}  \\circ L_{2}  \\circ L_{3} ) (t) \n",
    "$$\n",
    "Therefore we define a loss function\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\mathbf{W}) = \\frac{1}{M}\\sum_{i=1}^M (m * \\ddot y_\\mathbf{W}(t_i) + c * \\dot y_\\mathbf{W}(t_i) + k * y_\\mathbf{W}(t_i) - g(t) ) ^ 2 + (y_\\mathbf{W}(0) - y_0) ^ 2 + (\\dot y_\\mathbf{W}(0) - \\dot y_0) ^ 2\n",
    "$$\n",
    "Where sceond and third terms are the initial value losses. To minimize the loss function we choose Gradient descent algorithm\n",
    "$$\n",
    "--\n",
    "$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$  L_{o} = {\\large \\sigma} \\left( \n",
    "  \\begin{bmatrix}\n",
    " & {\\large W} & \\\\\n",
    "\n",
    "\n",
    " \n",
    "\\end{bmatrix} * \n",
    "\\begin{bmatrix}\n",
    "  \\\\\n",
    "{\\large x}   \\\\\n",
    "  \\\\\n",
    "\n",
    " \n",
    "\\end{bmatrix} +\n",
    "\\begin{bmatrix}\n",
    "  \\\\\n",
    "{\\large b}   \\\\\n",
    " \\\\\n",
    "\n",
    " \n",
    "\\end{bmatrix} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example \n",
    "with $m = 1, c = 0.1$ and $k = 1$. \n",
    "\n",
    "Consider the harmonic oszilator\n",
    "harmonischer oszilator\n",
    "$$\n",
    "\\ddot y + r * \\dot y + \\omega ^2 * y = B * cos(\\Omega * t),\n",
    "$$\n",
    "$$\n",
    "\\ddot y + 1 * \\dot y +  y = 1 * cos(\\Omega * t),\n",
    "$$\n",
    "a = 1\n",
    "b = 1\n",
    "c = 1\n",
    "y0 = 1.\n",
    "y0_prime = 0.\n",
    "\n",
    "In Python we can implement the traing loop with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs = 300):\n",
    "    trainable_vars = NN.trainable_variables\n",
    "    optimizer = GradientDescent()\n",
    "    for _ in range(epochs):\n",
    "        with tf.GradientTape(persistent=True) as tape: \n",
    "            loss = inh(train_t,NN,g)\n",
    "        grad = tape.gradient(loss, trainable_vars)\n",
    "        optimizer.apply_gradients(grad, trainable_vars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in which"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #https://www.tensorflow.org/guide/core/optimizers_core\n",
    "# class GradientDescent(tf.Module):\n",
    "\n",
    "#   def __init__(self, learning_rate=1e-3):\n",
    "#     # Initialize parameters\n",
    "#     self.learning_rate = learning_rate\n",
    "#     self.title = f\"Gradient descent optimizer: learning rate={self.learning_rate}\"\n",
    "\n",
    "#   def apply_gradients(self, grads, vars):\n",
    "#     # Update variables\n",
    "#     for grad, var in zip(grads, vars):\n",
    "#       var.assign_sub(self.learning_rate*grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #https://www.tensorflow.org/guide/core/optimizers_core\n",
    "# class GradientDescent(tf.Module):\n",
    "\n",
    "#   def __init__(self, learning_rate=1e-3):\n",
    "#     # Initialize parameters\n",
    "#     self.learning_rate = learning_rate\n",
    "#     self.title = f\"Gradient descent optimizer: learning rate={self.learning_rate}\"\n",
    "\n",
    "#   def apply_gradients(self, grads, vars):\n",
    "#     # Update variables\n",
    "#     for grad, var in zip(grads, vars):\n",
    "#       var.assign_sub(self.learning_rate*grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the above algorithm yields with calculated solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\frac{\\left(z - 1\\right) \\left(z + 1\\right) \\cos{\\left(z \\right)}}{z^{4} - z^{2} + 1}$"
      ],
      "text/plain": [
       "-(z - 1)*(z + 1)*cos(z)/(z**4 - z**2 + 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\frac{\\left(z - 1\\right) \\left(z + 1\\right) \\cos{\\left(z \\right)}}{z^{4} - z^{2} + 1} + \\frac{d}{d z} \\left(- \\frac{\\left(z - 1\\right) \\left(z + 1\\right) \\cos{\\left(z \\right)}}{z^{4} - z^{2} + 1}\\right) + \\frac{d^{2}}{d z^{2}} \\left(- \\frac{\\left(z - 1\\right) \\left(z + 1\\right) \\cos{\\left(z \\right)}}{z^{4} - z^{2} + 1}\\right)$"
      ],
      "text/plain": [
       "-(z - 1)*(z + 1)*cos(z)/(z**4 - z**2 + 1) + Derivative(-(z - 1)*(z + 1)*cos(z)/(z**4 - z**2 + 1), z) + Derivative(-(z - 1)*(z + 1)*cos(z)/(z**4 - z**2 + 1), (z, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Derivative(solution,z) + Derivative(Derivative(solution,z)) + solution )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
