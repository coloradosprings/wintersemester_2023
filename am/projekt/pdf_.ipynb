{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\frac{\\left(z - 1\\right) \\left(z + 1\\right) \\cos{\\left(z \\right)}}{z^{4} - z^{2} + 1}$"
      ],
      "text/plain": [
       "-(z - 1)*(z + 1)*cos(z)/(z**4 - z**2 + 1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculated solution\n",
    "z = symbols(\"z\",real=True)\n",
    "w,r,O,B = 1,1,1,1\n",
    "A = 1/(-z**2*O**2 + I*r*z*O + w**2)\n",
    "Z = A*E**(I*O*z)\n",
    "solution = factor( re(A)*re(E**(I*O*z)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuralNetwork = 0\n",
    "train_t = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "project applied machine learning,VO Applied machine learning (2023W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       " .t {\n",
       "\n",
       "    display: flex;\n",
       "    flex-direction: column;\n",
       "    justify-items: center;\n",
       "    justify-content: space-evenly;\n",
       "    margin: 5%;\n",
       "    width: 100%;\n",
       "    list-style-type: none;}\n",
       "\n",
       "\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "\n",
    " .t {\n",
    "\n",
    "    display: flex;\n",
    "    flex-direction: column;\n",
    "    justify-items: center;\n",
    "    justify-content: space-evenly;\n",
    "    margin: 5%;\n",
    "    width: 100%;\n",
    "    list-style-type: none;}\n",
    "\n",
    "\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"    \n",
    "display: flex;\n",
    "    /* background-color: #1F2937 ;  */\n",
    "    display: flex;\n",
    "    flex-direction: row;\n",
    "    justify-items: center;\n",
    "    justify-content: space-evenly;\n",
    "    margin: 5%;\n",
    "    width: 100%;\n",
    "    list-style-type: none;\"\n",
    "    >\n",
    "    <li>12031612<br>Josef Wagner\n",
    "    </li>\n",
    "\n",
    "    <li></li>\n",
    "    <li>VO Applied machine learning (2023W)\n",
    "    \n",
    "    <br>last project</li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">Project : Physics informed neural networks PINNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h3>Outline:</h3>\n",
    "<div style=\"    \n",
    "    display: flex;\n",
    "    flex-direction: column;\n",
    "    justify-items: center;\n",
    "    justify-content: space-evenly;\n",
    "    list-style-type: none;\n",
    "    margin-left: 50px;\"\n",
    "    >\n",
    "    <li ><a href='#graphs'>a)What is a PINN</a></li>\n",
    "    <li><a href='#oscilator'>b)example: harmonic oscilator</a></li>\n",
    "    <div style=\"margin-left: 15px;\" >\n",
    "    <li><a href='#training'>i)training</a></li>\n",
    "    <li> <a href='#CPINN'>ii)CPINN - Competitive PINNS </a></li>\n",
    "    </div>\n",
    "    <li> <a href='#ref'>references </a></li>\n",
    "\n",
    "</div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>a)What is a PINN?</h3>\n",
    "<a id='graphs'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We are trying to approximate a particular solution of second order inhomegenous ODE \n",
    "\n",
    "$$\n",
    "m * \\ddot y + c * \\dot y + k * y = g(t),\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "<!-- with $m = 1, c = 0.1$ and $k = 1$.  -->\n",
    "\n",
    "with a neural network of the form\n",
    "\n",
    "$$\n",
    "\n",
    "{  L_{i} = \\large \\sigma_{i} \\left({ \\begin{bmatrix}\n",
    "&  &  \\\\\n",
    "& {\\large W_{i}} & \\\\\n",
    "&  &  \\\\\n",
    "\n",
    " \n",
    "\\end{bmatrix} * \n",
    "\\begin{bmatrix}\n",
    "  \\\\\n",
    "{\\large x_{i}}   \\\\\n",
    "  \\\\\n",
    "\n",
    " \n",
    "\\end{bmatrix} +\n",
    "\\begin{bmatrix}\n",
    "  \\\\\n",
    "{\\large b_{i}}   \\\\\n",
    " \\\\\n",
    "\n",
    " \n",
    "\\end{bmatrix} \n",
    "\n",
    "\n",
    " }\\right) }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "$$\n",
    "N(t) =  (L_{1}  \\circ L_{2}  \\circ L_{3} \\circ L_{o}) (t) \n",
    "$$\n",
    "<!--  -->\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\sigma_{i}$ is an yet undetermed activation function. and $L_o \\rightarrow  \\mathbb{R}$ is the output neuron of the form.\n",
    "$$  L_{o} = {\\large \\sigma} \\left( \n",
    "  \\begin{bmatrix}\n",
    " & {\\large w} & \\\\\n",
    "\n",
    "\n",
    " \n",
    "\\end{bmatrix} * \n",
    "\\begin{bmatrix}\n",
    "  \\\\\n",
    "{\\large x}   \\\\\n",
    "  \\\\\n",
    "\n",
    " \n",
    "\\end{bmatrix} +\n",
    " \\lambda \\right)$$\n",
    "\n",
    " \n",
    "\n",
    "Therefore we define a loss function\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\mathbf{W}) = \\frac{1}{M}\\sum_{i=1}^M { (m * \\ddot {N}(t_i) + c * \\dot {N}(t_i) + k * {N}(t_i) - g(t) ) ^  2 }+ \\textcolor{blue}{({N}(0) - y_0) ^ 2 + (\\dot {N}(0) - \\dot y_0) ^ 2}\n",
    "$$\n",
    "Where sceond and third terms are the initial value losses. To minimize the loss function we choose Stochastic Gradient descent algorithm.\n",
    "$$\n",
    "--\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3  id='oscilator'>b)example: harmonic oscilator</h3>\n",
    "<h4  id='training'>i)training</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Consider the harmonic oscilator\n",
    "\n",
    "$$\n",
    "\\ddot y + r * \\dot y + \\omega ^2 * y = B * cos(\\Omega * t),\n",
    "$$\n",
    "for simplicity we set all parameters to 1,\n",
    "\n",
    "$$\n",
    "\\ddot y + \\dot y +  y = cos(t),\n",
    "$$\n",
    "and initialize the  $L_i$ ,\n",
    "$$\n",
    "{  L_{i} = \\large tanh \\left({ \\begin{bmatrix}\n",
    "&  &  \\\\\n",
    "& 32 \\times 32 &\\\\\n",
    "&  &  \\\\\n",
    "\n",
    " \n",
    "\\end{bmatrix} * \n",
    "\\begin{bmatrix}\n",
    "  \\\\\n",
    "{\\large x_{i}}   \\\\\n",
    "  \\\\\n",
    "\n",
    " \n",
    "\\end{bmatrix} +\n",
    "\\begin{bmatrix}\n",
    "  \\\\\n",
    "32   \\\\\n",
    " \\\\\n",
    "\n",
    " \n",
    "\\end{bmatrix} \n",
    "\n",
    "\n",
    " }\\right) }\n",
    "\n",
    " $$\n",
    "with values in [0,1). The calculated solution of the equation is \n",
    "$$\n",
    "y_p(t) = sin(t).\n",
    "\n",
    "$$\n",
    "\n",
    "\n",
    "In Python we can implement the traing loop for example with tensorflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs = 300):\n",
    "    trainable_vars = NeuralNetwork.trainable_variables()\n",
    "    optimizer = tf.optimizers.SGD(learning_rate=0.01)\n",
    "    for _ in range(epochs):\n",
    "        with tf.GradientTape(persistent=True) as tape: \n",
    "            loss = loss(train_t,NeuralNetwork,g)\n",
    "        grad = tape.gradient(loss, trainable_vars)\n",
    "        optimizer.apply_gradients(grad, trainable_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is we calculate the gradient with respect to each variable and shift the variable in the direction of the gradient accordingly,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting the calculated solution and the predicted solution in blue for  values in  [0,2]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"png/output.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the error with respect to the $L_2 $ norm,with trapazoid integral yields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ || NeuralNetwork(t) - sin(t) ||_{L_2}  =  0.20278955 .$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we plot the loss, we can see its convergening to $ \\approx0.28.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"png/loss.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "--\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 id='CPINN'> ii)CPINN - Competitive PINNS </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying to tackle this further by adding a discriminator neural network $ T(t) $ ,\n",
    "$$ \\mathcal{L}(N,T,t) = \\frac{1}{M}\\sum_{i=1}^M  T(t) * ( \\ddot N(t_i) + \\dot N(t_i) + N(t_i) )^2$$\n",
    "\n",
    " with the according the optimization problem,\n",
    "$$ max_T \\phantom,   min_N \\phantom,   \\mathcal{L}(N,T,t). $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we try stochastic gradient descent for T and for N, that is  $  SGD_{learnable variables \\phantom,  L }( - \\mathcal{L}(N,T,t)) $ and $ SGD_{learnable variables\\phantom, NN }( \\mathcal{L}(N,T,t))$ for each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting the loss we see it seems to converge to the 'Nash equilibrium'.    $ (T,NN) \\rightarrow (0,y) $  which would be a solution for the equation. \n",
    "This is not expected because trying to apply SGD seperatly just works for specific zero sum optimization problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"png/losscpin.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the resulting loss plot and $L_2$ norm is now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ || NeuralNetwork(t) - sin(t) ||_{L_2}  = 0.18570352  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One has to consider Optimizers for zero sum problems  for example Competitive Gradient Descent or Sympletic Gradient Adjustment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 id='references'>references</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"    \n",
    "    display: flex;\n",
    "    flex-direction: column;\n",
    "    justify-items: center;\n",
    "    justify-content: space-evenly;\n",
    "    list-style-type: none;\n",
    "    margin-left: 50px;\"\n",
    "    >\n",
    "<li> Prof. Seungchul Lee   -  <i>  Physics-informed Neural Networks (PINN) </i><a href'https://i-systems.github.io/tutorial/KSNVE/220525/01_PINN.html#3.2.-Lab-1%3A-Simple-Example'> \"https://i-systems.github.io/tutorial/KSNVE/220525/01_PINN.html#3.2.-Lab-1%3A-Simple-Example \"</a></li> <br>\n",
    "<li> Lukas Exl, Sebastian Schaffer, Norbert J. Mauser   -   <i> Vorlesungsskript Angewandtes Maschinelles  Lernen </i> </li><br>\n",
    " <li>Benoit Liquet, Sarat Moka, and Yoni Nazarathy   -   <i> The Mathematical Engineering of Deep Learning (2021) </i> <a href'https://deeplearningmath.org/general-fully-connected-neural-networks'>https://deeplearningmath.org/general-fully-connected-neural-networks</a> </li><br>\n",
    " <li>Qi Zeng, Yash Kothari, Spencer H. Bryngelson & Florian Sch√§fer   -   <i> COMPETITIVE PHYSICS INFORMED NETWORKS </i></li> <br>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changing the loss Function from mean squared error to least squares\n",
    "we can change the Optimizer to Gradient Descent and the loss function to least square i.e "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ansatz of the form $$ e^{NN(t)} $$ \n",
    "Neural Networks for parameter depended equaation\n",
    "Changing Loss funcation to least squares $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #https://www.tensorflow.org/guide/core/optimizers_core\n",
    "# class GradientDescent(tf.Module):\n",
    "\n",
    "#   def __init__(self, learning_rate=1e-3):\n",
    "#     # Initialize parameters\n",
    "#     self.learning_rate = learning_rate\n",
    "#     self.title = f\"Gradient descent optimizer: learning rate={self.learning_rate}\"\n",
    "\n",
    "#   def apply_gradients(self, grads, vars):\n",
    "#     # Update variables\n",
    "#     for grad, var in zip(grads, vars):\n",
    "#       var.assign_sub(self.learning_rate*grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #https://www.tensorflow.org/guide/core/optimizers_core\n",
    "# class GradientDescent(tf.Module):\n",
    "\n",
    "#   def __init__(self, learning_rate=1e-3):\n",
    "#     # Initialize parameters\n",
    "#     self.learning_rate = learning_rate\n",
    "#     self.title = f\"Gradient descent optimizer: learning rate={self.learning_rate}\"\n",
    "\n",
    "#   def apply_gradients(self, grads, vars):\n",
    "#     # Update variables\n",
    "#     for grad, var in zip(grads, vars):\n",
    "#       var.assign_sub(self.learning_rate*grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the above algorithm yields with calculated solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\frac{\\left(z - 1\\right) \\left(z + 1\\right) \\cos{\\left(z \\right)}}{z^{4} - z^{2} + 1}$"
      ],
      "text/plain": [
       "-(z - 1)*(z + 1)*cos(z)/(z**4 - z**2 + 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\frac{\\left(z - 1\\right) \\left(z + 1\\right) \\cos{\\left(z \\right)}}{z^{4} - z^{2} + 1} + \\frac{d}{d z} \\left(- \\frac{\\left(z - 1\\right) \\left(z + 1\\right) \\cos{\\left(z \\right)}}{z^{4} - z^{2} + 1}\\right) + \\frac{d^{2}}{d z^{2}} \\left(- \\frac{\\left(z - 1\\right) \\left(z + 1\\right) \\cos{\\left(z \\right)}}{z^{4} - z^{2} + 1}\\right)$"
      ],
      "text/plain": [
       "-(z - 1)*(z + 1)*cos(z)/(z**4 - z**2 + 1) + Derivative(-(z - 1)*(z + 1)*cos(z)/(z**4 - z**2 + 1), z) + Derivative(-(z - 1)*(z + 1)*cos(z)/(z**4 - z**2 + 1), (z, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Derivative(solution,z) + Derivative(Derivative(solution,z)) + solution )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
